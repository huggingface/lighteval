<!--
Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# 保存和读取结果

## 本地保存结果

Lighteval将自动在使用`--output-dir`选项设置的目录中保存结果和评估详情。结果将保存在`{output_dir}/results/{model_name}/results_{timestamp}.json`中。[这里有一个结果文件的示例](#结果文件示例)。输出路径可以是任何符合[fsspec](https://filesystem-spec.readthedocs.io/en/latest/index.html)的路径（本地、s3、hf hub、gdrive、ftp等）。

要保存评估的详细信息，您可以使用`--save-details`选项。详细信息将保存在parquet文件`{output_dir}/details/{model_name}/{timestamp}/details_{task}_{timestamp}.parquet`中。

## 将结果推送到HuggingFace hub

您可以将结果和评估详情推送到HuggingFace hub。要这样做，您需要设置`--push-to-hub`以及`--results-org`选项。结果将保存在名为`{results_org}/{model_org}/{model_name}`的数据集中。要推送详细信息，您需要设置`--save-details`选项。
默认情况下，创建的数据集将是私有的，您可以通过设置`--public-run`选项使其公开。


## 将结果推送到Tensorboard

您可以通过设置`--push-to-tensorboard`将结果推送到Tensorboard。这将在使用`--results-org`选项设置的HF组织中创建一个Tensorboard仪表板。


## 将结果推送到WandB

您可以通过设置`--wandb`将结果推送到WandB。这将初始化一个WandB运行并记录结果。

Wandb参数需要在您的环境变量中设置。

```
export WANDB_PROJECT="lighteval"
```

您可以在[wandb文档](https://docs.wandb.ai/guides/track/environment-variables/)中找到变量列表。


## 如何加载和研究详细信息

### 从本地详细信息文件加载

```python
from datasets import load_dataset
import os

output_dir = "evals_doc"
model_name = "HuggingFaceH4/zephyr-7b-beta"
timestamp = "latest"
task = "lighteval|gsm8k|0"

if timestamp == "latest":
    path = f"{output_dir}/details/{model_org}/{model_name}/*/"
    timestamps = glob.glob(path)
    timestamp = sorted(timestamps)[-1].split("/")[-2]
    print(f"Latest timestamp: {timestamp}")

details_path = f"{output_dir}/details/{model_name}/{timestamp}/details_{task}_{timestamp}.parquet"

# 加载详细信息
details = load_dataset("parquet", data_files=details_path, split="train")

for detail in details:
    print(detail)
```

### 从HuggingFace hub加载

```python
from datasets import load_dataset

results_org = "SaylorTwift"
model_name = "HuggingFaceH4/zephyr-7b-beta"
sanitized_model_name = model_name.replace("/", "__")
task = "lighteval|gsm8k|0"
public_run = False

dataset_path = f"{results_org}/details_{sanitized_model_name}{'_private' if not public_run else ''}"
details = load_dataset(dataset_path, task.replace("|", "_"), split="latest")

for detail in details:
    print(detail)
```


详细信息文件包含以下列：
- `choices`：在多选任务的情况下，向模型呈现的选项。
- `gold`：黄金答案。
- `gold_index`：黄金答案在选项列表中的索引。
- `cont_tokens`：续写的令牌。
- `example`：文本形式的输入。
- `full_prompt`：完整提示，将输入到模型中。
- `input_tokens`：完整提示的令牌。
- `instruction`：给模型的指令。
- `metrics`：为示例计算的指标。
- `num_asked_few_shots`：要求模型的少样本数量。
- `num_effective_few_shots`：有效的少样本数量。
- `padded`：输入是否被填充。
- `pred_logits`：模型的logits。
- `predictions`：模型的预测。
- `specifics`：任务的具体细节。
- `truncated`：输入是否被截断。


## 结果文件示例

```json
{
  "config_general": {
    "lighteval_sha": "203045a8431bc9b77245c9998e05fc54509ea07f",
    "num_fewshot_seeds": 1,
    "override_batch_size": 1,
    "max_samples": 1,
    "job_id": "",
    "start_time": 620979.879320166,
    "end_time": 621004.632108041,
    "total_evaluation_time_secondes": "24.752787875011563",
    "model_name": "gpt2",
    "model_sha": "607a30d783dfa663caf39e06633721c8d4cfcd7e",
    "model_dtype": null,
    "model_size": "476.2 MB"
  },
  "results": {
    "lighteval|gsm8k|0": {
      "qem": 0.0,
      "qem_stderr": 0.0,
      "maj@8": 0.0,
      "maj@8_stderr": 0.0
    },
    "all": {
      "qem": 0.0,
      "qem_stderr": 0.0,
      "maj@8": 0.0,
      "maj@8_stderr": 0.0
    }
  },
  "versions": {
    "lighteval|gsm8k|0": 0
  },
  "config_tasks": {
    "lighteval|gsm8k": {
      "name": "gsm8k",
      "prompt_function": "gsm8k",
      "hf_repo": "gsm8k",
      "hf_subset": "main",
      "metric": [
        {
          "metric_name": "qem",
          "higher_is_better": true,
          "category": "3",
          "use_case": "5",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        },
        {
          "metric_name": "maj@8",
          "higher_is_better": true,
          "category": "5",
          "use_case": "5",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_avail_splits": [
        "train",
        "test"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": null,
      "few_shots_select": "random_sampling_from_train",
      "generation_size": 256,
      "generation_grammar": null,
      "stop_sequence": [
        "Question="
      ],
      "num_samples": null,
      "suite": [
        "lighteval"
      ],
      "original_num_docs": 1319,
      "effective_num_docs": 1,
      "trust_dataset": true,
      "must_remove_duplicate_docs": null,
      "version": 0
    }
  }
} 