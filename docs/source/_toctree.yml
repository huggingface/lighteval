- sections:
  - local: index
    title: ðŸ¤— Lighteval
  - local: installation
    title: Installation
  - local: quicktour
    title: Quicktour
  title: Getting started
- sections:
  - local: inspect-ai
    title: Examples using Inspect-AI
  - local: saving-and-reading-results
    title: Save and read results
  - local: caching
    title: Caching
  - local: using-the-python-api
    title: Use the Python API
  - local: adding-a-custom-task
    title: Add a custom task
  - local: offline-evaluation
    title: Offline evaluation
  - local: adding-a-new-metric
    title: Add a custom metric
  - local: evaluating-a-custom-model
    title: Evaluate a custom model
  - local: use-inference-providers-as-backend
    title: Use HF's inference providers as backend
  - local: use-litellm-as-backend
    title: Use litellm as backend
  - local: use-vllm-as-backend
    title: Use vllm as backend
  - local: use-sglang-as-backend
    title: Use SGLang as backend
  - local: use-huggingface-inference-endpoints-or-tgi-as-backend
    title: Use Hugging Face inference endpoints or TGI as backend
  - local: contributing-to-multilingual-evaluations
    title: Contributing to multilingual evaluations
  title: Guides
- sections:
  - local: metric-list
    title: Available Metrics
  - local: available-tasks
    title: Available Tasks
  title: API
- sections:
  - sections:
    - local: package_reference/evaluation_tracker
      title: EvaluationTracker
    - local: package_reference/models
      title: Model Configs
    - local: package_reference/pipeline
      title: Pipeline
    title: Main classes
  - local: package_reference/metrics
    title: Metrics
  - local: package_reference/tasks
    title: Tasks
  - local: package_reference/logging
    title: Logging
  - local: package_reference/models_outputs
    title: ModelResponse
  - local: package_reference/doc
    title: Doc
  title: Reference
